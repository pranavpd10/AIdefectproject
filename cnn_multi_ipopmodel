import random
import os
import pandas as pd
import numpy as np
import csv
import sklearn
import operator
from sklearn.model_selection import train_test_split
import keras
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from keras import backend as k
from tensorflow import keras
from tensorflow.keras import layers
%matplotlib
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/drive')

!cp '/drive/My Drive/pro_trdata/scale_data/chop_dataf_scl.csv' 'chop_dataf_scl.csv'

var = pd.read_csv('chop_dataf_scl.csv')

x = var[var.columns[8:]]
y = var[var.columns[:8]]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.08, random_state=10)
print(x_train.shape); print(x_test.shape)

dp_input = x_train[x_train.columns[:3]]
cls_input = x_train[x_train.columns[3:]]
dp_target = y_train[y_train.columns[0]]
cls_target = y_train[y_train.columns[1:8]]

clsnofdatax = cls_input.shape[0]
clsinputrx = cls_input.shape[1]
dpinputrx= dp_input.shape[1]

print(clsnofdatax, clsinputrx, dpinputrx)

cls_input = cls_input.to_numpy()

cls_input = cls_input.reshape(clsnofdatax,1,clsinputrx,1)

inputdp = keras.Input(shape=(dpinputrx,), name='angroup')
x = layers.Dense(10, activation='relu', name='dense_1')(inputdp)
x = layers.Dense(10, activation='relu', name='dense_2')(x)
# x = layers.Dense(5, activation='relu', name='dense_3')(x)


inputcnn = keras.Input(shape=(1,clsinputrx,1), name='digits')
conv_1 = keras.layers.Conv2D(15, (1, 3), activation='relu')(inputcnn)
conv_2 = keras.layers.Conv2D(30, (1, 3), activation='relu')(conv_1)
conv_3 = keras.layers.Conv2D(60, (1, 3), activation='relu')(conv_2)
conv_4 = keras.layers.Conv2D(120, (1, 3), activation='relu')(conv_3)
flatten = keras.layers.Flatten()(conv_4)


conlay = layers.concatenate([flatten, x]) #conlay concate layer
flade1 = layers.Dense(400, activation = 'relu', name='flade1')(conlay) # flade flatten and dense
fladem1 = layers.Dense(200, activation = 'relu', name='fladem1')(flade1)
flade2 = layers.Dense(70, activation = 'relu', name='flade2')(fladem1)
depth_output = layers.Dense(1, activation = 'linear', name='depth_output')(flade2)
class_output = layers.Dense(7, activation = 'softmax', name='class_output')(flade2)

model = keras.Model(inputs=[inputdp, inputcnn ], outputs=[depth_output, class_output])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0015),
    loss={'depth_output': keras.losses.MeanSquaredError(),
          'class_output': keras.losses.CategoricalCrossentropy()},
    metrics={'depth_output': [keras.metrics.MeanAbsoluteError()],
             'class_output': [keras.metrics.CategoricalAccuracy()]})
model.fit([dp_input, cls_input],
          [dp_target, cls_target], # first list for multi i/p , next list for o/p targets
          batch_size=10,
          epochs=25,
          validation_split=0.15)
